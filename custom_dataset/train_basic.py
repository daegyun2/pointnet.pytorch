# custom_dataset/train.py
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from pointnet_regression import PointNetRegression
from dataset import PointCloudRegressionDataset
import os
import numpy as np

# í•˜ì´í¼íŒŒë¼ë¯¸í„°
batch_size = 32
epochs = 100
learning_rate = 1e-4
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

print(f"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ device: {device}")

# ë°ì´í„°ì…‹ & ë°ì´í„°ë¡œë”
dataset = PointCloudRegressionDataset(root_dir='../data/')
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)

# ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €
model = PointNetRegression().to(device)
criterion_position = nn.MSELoss()
criterion_hand = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Learning Rate Scheduler
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=5, verbose=True
)

# Early Stopping
best_loss = float('inf')
no_improve = 0
patience = 10

# Checkpoint ì €ì¥ ë””ë ‰í† ë¦¬
os.makedirs('checkpoints', exist_ok=True)

# í•™ìŠµ ë£¨í”„
for epoch in range(epochs):
    model.train()
    epoch_loss = 0.0
    epoch_pos_loss = 0.0
    epoch_hand_loss = 0.0
    
    hand_correct = 0
    hand_total = 0
    
    for points, body_center, hand_label in dataloader:
        points = points.to(device)
        body_center = body_center.to(device)
        hand_label = hand_label.to(device)
        
        # Transpose: (batch, N, 3) -> (batch, 3, N)
        points = points.transpose(2, 1)
        
        optimizer.zero_grad()
        
        # Forward
        pred_position, hand_logits = model(points)
        
        # Loss ê³„ì‚°
        loss_pos = criterion_position(pred_position, body_center)
        loss_hand = criterion_hand(hand_logits, hand_label)
        
        # Total loss (ìœ„ì¹˜ loss + 0.5 * ì† loss)
        loss = loss_pos + 0.5 * loss_hand
        
        # Backward
        loss.backward()
        optimizer.step()
        
        # í†µê³„
        epoch_loss += loss.item()
        epoch_pos_loss += loss_pos.item()
        epoch_hand_loss += loss_hand.item()
        
        # ì† ë¶„ë¥˜ ì •í™•ë„
        _, predicted = torch.max(hand_logits, 1)
        hand_total += hand_label.size(0)
        hand_correct += (predicted == hand_label).sum().item()
    
    # í‰ê·  ê³„ì‚°
    avg_loss = epoch_loss / len(dataloader)
    avg_pos_loss = epoch_pos_loss / len(dataloader)
    avg_hand_loss = epoch_hand_loss / len(dataloader)
    hand_acc = 100.0 * hand_correct / hand_total
    
    # Learning rate
    current_lr = optimizer.param_groups[0]['lr']
    
    # ì¶œë ¥
    print(f"[Epoch {epoch+1}/{epochs}] "
          f"Loss: {avg_loss:.6f} | "
          f"Pos: {avg_pos_loss:.6f} | "
          f"Hand: {avg_hand_loss:.6f} | "
          f"Hand Acc: {hand_acc:.2f}% | "
          f"LR: {current_lr:.6f}")
    
    # Scheduler ì—…ë°ì´íŠ¸
    scheduler.step(avg_loss)
    
    # Early Stopping & Best Model ì €ì¥
    if avg_loss < best_loss:
        best_loss = avg_loss
        no_improve = 0
        torch.save(model.state_dict(), 'checkpoints/best_model.pth')
        print(f"  âœ“ New best model saved! (Loss: {best_loss:.6f})")
    else:
        no_improve += 1
        if no_improve < patience:
            print(f"  â†’ No improvement for {no_improve}/{patience} epochs")
    
    # Early Stopping ì²´í¬
    if no_improve >= patience:
        print(f"\nEarly stopping triggered! No improvement for {patience} epochs.")
        break
    
    # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    if (epoch + 1) % 10 == 0:
        torch.save(model.state_dict(), f'checkpoints/model_epoch_{epoch+1}.pth')
        print(f"  ğŸ’¾ Checkpoint saved: model_epoch_{epoch+1}.pth")

# ìµœì¢… ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), 'checkpoints/model_final.pth')
print("\ní•™ìŠµ ì™„ë£Œ! ìµœì¢… ëª¨ë¸ì´ 'checkpoints/model_final.pth'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"Best model: checkpoints/best_model.pth (Loss: {best_loss:.6f})")

# # custom_dataset/train.py
# import torch
# from dataset import PointCloudRegressionDataset
# from pointnet_regression import PointNetRegression
# from torch.utils.data import DataLoader
# import os

# batch_size = 32
# epochs = 100
# learning_rate = 0.0001
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# print(f"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ device: {device}")

# dataset = PointCloudRegressionDataset(root_dir='../data/')
# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# model = PointNetRegression().to(device)
# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
# criterion = torch.nn.MSELoss()

# os.makedirs('checkpoints', exist_ok=True)

# model.train()
# for epoch in range(epochs):
#     epoch_loss = 0.0
#     for points, gt in dataloader:
#         points, gt = points.to(device), gt.to(device)
#         points = points.transpose(2, 1)

#         optimizer.zero_grad()
#         output = model(points)
#         loss = criterion(output, gt)
#         loss.backward()
#         optimizer.step()

#         epoch_loss += loss.item()

#     avg_loss = epoch_loss / len(dataloader)
#     print(f"[Epoch {epoch+1}/{epochs}] Avg Loss: {avg_loss:.6f}")

#     if (epoch + 1) % 10 == 0:
#         torch.save(model.state_dict(), f'checkpoints/model_epoch_{epoch+1}.pth')

# torch.save(model.state_dict(), 'checkpoints/model_final.pth')
# print("Training finished!")
